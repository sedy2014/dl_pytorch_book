{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = \"$\" + ''.join(chr(ord('a') + i) for i in range(26))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "char_to_index = {}\n",
    "index_to_char = {}\n",
    "for index, char in enumerate(vocab):\n",
    "    char_to_index[char] = index\n",
    "    index_to_char[index] = char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================== PREVIOUS CODE ===============================\n",
    "vocab = \"$\" + ''.join(chr(ord('a') + i) for i in range(26))\n",
    "vocab_size = len(vocab)\n",
    "# Create dictionaries for character to index and index to character\n",
    "ch_to_i = {char: i for i, char in enumerate(vocab)}\n",
    "i_to_ch = {i: char for i, char in enumerate(vocab)}\n",
    "\n",
    "# Define encode and decode functions\n",
    "encode = lambda word: torch.tensor([ch_to_i[c] for c in word])\n",
    "decode = lambda tensor_i: ''.join(i_to_ch[i.item()] for i in tensor_i)\n",
    "\n",
    "# Get data\n",
    "names = []\n",
    "with open('../data/p2ch9/names_2022.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        name, _, _= line.lower().strip().split(',')\n",
    "        names.append(name)\n",
    "\n",
    "# filter out names 10 characters and longer\n",
    "names = [name for name in names if len(name) < 10]\n",
    "# Add special character boundary to names\n",
    "names = ['$' + name + '$' for name in names]\n",
    "\n",
    "# Length of max name\n",
    "max_name_length = max(len(name) for name in names)\n",
    "longest_name = max(names, key=len)\n",
    "longest_name_index = names.index(longest_name)\n",
    "\n",
    "# Create a function to get a batch of data\n",
    "names_index = [torch.tensor([ch_to_i[char] for char in name]) for name in names]\n",
    "targets_index = [name_index[1:] for name_index in names_index]\n",
    "names_index[0], targets_index[0]\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "X = pad_sequence(names_index, batch_first=True, padding_value=0)\n",
    "# trick to pad Y with with -1 and the same size as X\n",
    "targets_index.append(X[0])\n",
    "Y = pad_sequence(targets_index, batch_first=True, padding_value=-1)[:-1]\n",
    "\n",
    "def get_batch(batch_size=64):\n",
    "    random_idx = torch.randint(0, X.size(0), (batch_size,))\n",
    "    batch = X[random_idx]\n",
    "    labels = Y[random_idx]\n",
    "    return batch, labels\n",
    "batch, labels = get_batch()\n",
    "\n",
    "def train(model, optimizer, num_steps=10_001, loss_report_interval=1_000):\n",
    "    losses = []\n",
    "    for i in range(1, num_steps):\n",
    "        inputs, labels = get_batch()\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(inputs)\n",
    "        loss = F.cross_entropy(logits.view(-1, logits.shape[-1]), labels.view(-1), ignore_index=-1)\n",
    "        losses.append(loss.item())\n",
    "        if i % loss_report_interval == 0:\n",
    "            print(f'Average loss at step {i}: {sum(losses[-loss_report_interval:]) / loss_report_interval:.4f}')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def generate_samples(model, num_samples=1, max_len=max_name_length):\n",
    "    sequences = torch.zeros((num_samples, 1)).int()\n",
    "    for _ in range(max_len):\n",
    "        logits = model(sequences)\n",
    "        logits = logits[:, -1, :]\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        sequences = torch.cat((sequences, idx_next), dim=1)\n",
    "\n",
    "    for sequence in sequences:\n",
    "        indices = torch.where(sequence == 0)[0]\n",
    "        end = indices[1] if len(indices) > 1 else max_len\n",
    "        sequence = sequence[1:end]\n",
    "        print(decode(sequence))\n",
    "# =============================== FINISH PREVIOUS CODE ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names_to_indices = []\n",
    "all_targets_to_indices = []\n",
    "for name in names:\n",
    "    name_to_indices = []\n",
    "    for char in name:\n",
    "        name_to_indices.append(char_to_index[char])\n",
    "    all_names_to_indices.append(torch.tensor(name_to_indices))\n",
    "    all_targets_to_indices.append(torch.tensor(name_to_indices[1:]))\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"name {i}: {all_names_to_indices[i]}\")\n",
    "    print(f\"target {i}: {all_targets_to_indices[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "X = pad_sequence(all_names_to_indices, batch_first=True)\n",
    "print(X.shape)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pad_sequence(\n",
    "    all_targets_to_indices + [X[-1]], \n",
    "    batch_first=True, \n",
    "    padding_value=-1)\n",
    "Y = Y[:-1]\n",
    "print(Y.shape)\n",
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n",
      "torch.Size([2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 6, 22, 38],\n",
       "        [54, 70, 86]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(0, 24).view(2, 3, 4)\n",
    "print(t)\n",
    "sum_t = t.sum(dim=-1)\n",
    "print(sum_t.shape)\n",
    "sum_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12, 15, 18, 21]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.1238, 1.6097, 1.1210],\n",
      "         [1.0748, 1.4402, 1.0530],\n",
      "         [1.2922, 1.6018, 1.1130],\n",
      "         [1.2236, 1.5888, 1.1344]]])\n",
      "tensor([[[2.0750, 1.8136, 0.4190],\n",
      "         [2.5313, 1.9086, 0.4521],\n",
      "         [2.0095, 1.5816, 0.3130],\n",
      "         [2.3691, 1.8376, 0.4426]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[2.0750, 1.8136, 0.4190],\n",
       "         [2.5313, 1.9086, 0.4521],\n",
       "         [2.0095, 1.5816, 0.3130],\n",
       "         [2.3691, 1.8376, 0.4426]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.rand(1, 4, 3) # <1>\n",
    "batch_size, sequence_length, feature_size = x.shape\n",
    "\n",
    "query = F.linear(x, weight=torch.rand(3, 3), bias=torch.rand(3))\n",
    "key = F.linear(x, weight=torch.rand(3, 3), bias=torch.rand(3))\n",
    "value = F.linear(x, weight=torch.rand(3, 3), bias=torch.rand(3))\n",
    "\n",
    "def scaled_dot_product_causal_attention(q, k, v):\n",
    "    # assumes batch dimension is present\n",
    "    attn_weights = q @ k.transpose(1, 2) # <2>\n",
    "    # create a mask to prevent the model from attending to future tokens\n",
    "    mask = torch.tril(torch.ones(attn_weights.shape[1:]), diagonal=0) # <3>\n",
    "    attn_weights = attn_weights.masked_fill(mask == 0, value=float('-inf'))\n",
    "    # normalize the attention weights\n",
    "    attn_weights = attn_weights / torch.sqrt(torch.tensor(k.shape[-1]).float()) # <4>\n",
    "    attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "    output = attn_weights @ v\n",
    "    return output, attn_weights\n",
    "\n",
    "output, attn_weights = scaled_dot_product_causal_attention(query, key, value)\n",
    "print(output)\n",
    "\n",
    "# Add an additional dimension for the heads\n",
    "num_heads = 2\n",
    "\n",
    "query = F.linear(x, weight=torch.rand(3, 3), bias=torch.rand(3))\n",
    "key = F.linear(x, weight=torch.rand(3, 3), bias=torch.rand(3))\n",
    "value = F.linear(x, weight=torch.rand(3, 3), bias=torch.rand(3))\n",
    "\n",
    "# Split the transformed sequence across multiple heads\n",
    "query = query.view(x.shape[0], num_heads, x.shape[1] // num_heads, x.shape[2])\n",
    "key = key.view(x.shape[0], num_heads, x.shape[1] // num_heads, x.shape[2])\n",
    "value = value.view(x.shape[0], num_heads, x.shape[1] // num_heads, x.shape[2])\n",
    "\n",
    "def scaled_dot_product_causal_attention(q, k, v):\n",
    "    # assumes batch dimension is present\n",
    "    attn_weights = q @ k.transpose(-2, -1)  # <2>\n",
    "    # create a mask to prevent the model from attending to future tokens\n",
    "    mask = torch.tril(torch.ones(attn_weights.shape[-2:]), diagonal=0)  # <3>\n",
    "    attn_weights = attn_weights.masked_fill(mask == 0, value=float('-inf'))\n",
    "    # normalize the attention weights\n",
    "    attn_weights = attn_weights / torch.sqrt(torch.tensor(k.shape[-1]).float())  # <4>\n",
    "    attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "    output = attn_weights @ v\n",
    "    return output, attn_weights\n",
    "\n",
    "output, attn_weights = scaled_dot_product_causal_attention(query, key, value)\n",
    "# Combine the outputs from all heads\n",
    "output = output.transpose(1, 2).contiguous().view(batch_size, sequence_length, feature_size)\n",
    "print(output)\n",
    "\n",
    "expected_output = F.scaled_dot_product_attention(query, key, value, is_causal=True)\n",
    "expected_output = expected_output.transpose(1, 2).contiguous().view(batch_size, sequence_length, feature_size)\n",
    "expected_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, n_embd, num_heads=4, n_hidden=64):\n",
    "        super().__init__()\n",
    "        assert n_embd % num_heads == 0, \"Embedding dimension must be divisible by the number of heads\"\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = n_embd // num_heads\n",
    "\n",
    "        self.query_proj = nn.Linear(n_embd, n_embd)\n",
    "        self.key_proj = nn.Linear(n_embd, n_embd)\n",
    "        self.value_proj = nn.Linear(n_embd, n_embd)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_embd)\n",
    "        )\n",
    "\n",
    "        # Layernorms\n",
    "        self.norm_1 = nn.LayerNorm(n_embd)\n",
    "        self.norm_2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, sequence_length, _ = x.shape\n",
    "\n",
    "        q = self.query_proj(x)\n",
    "        k = self.key_proj(x)\n",
    "        v = self.value_proj(x)\n",
    "\n",
    "        # multiheaded attention\n",
    "        q = q.view(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        k = k.view(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = v.view(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # attention\n",
    "        attn_weights = F.scaled_dot_product_attention(q, k, v, is_causal=True)\n",
    "\n",
    "        # multiple heads concatenation\n",
    "        attn_weights = attn_weights.transpose(1, 2).contiguous().view(batch_size, sequence_length, -1)\n",
    "\n",
    "        # norm and residual connections here\n",
    "        x = self.norm_1(x + attn_weights)\n",
    "        x = self.norm_2(x + self.mlp(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/howardhuang/Code/my_own/DeepLearningWithPytorch-SecondEdition/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, n_embd, vocab_size, block_size, num_blocks=6):\n",
    "        super().__init__()\n",
    "        self.char_embedding = nn.Embedding(vocab_size, n_embd)\n",
    "        self.positional_embedding = nn.Embedding(block_size, n_embd)\n",
    "\n",
    "        self.transformer_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(n_embd) for _ in range(num_blocks)]\n",
    "        )\n",
    "\n",
    "        self.output_proj = nn.Linear(n_embd, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, seq_len = x.shape\n",
    "\n",
    "        pos_embd = self.positional_embedding(torch.arange(seq_len)) #  <1>\n",
    "        char_embd = self.char_embedding(x)\n",
    "        x = char_embd + pos_embd\n",
    "        x = self.transformer_blocks(x)\n",
    "        x = self.output_proj(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "n_embd = 64\n",
    "model = Transformer(n_embd, vocab_size, block_size=max_name_length)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 3, 9, 5, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = get_batch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "writer.add_graph(model, x)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "\u001b[1mSanta\u001b[0m\n",
      "\n",
      "This Application is not yet enabled on this computerFor security, this application must be enabled first before it can be opened.Click \"Next Steps ...\" if you want to run this application. Otherwise, click \"Ignore\" to dismiss this message.If you keep seeing this message a minute... ...After allowing, you need to manually sync Santa rules...After ignoring, you have a daemon/cron repeatedly restartingIf you are not sure what this prompt is about, please check this announcement. Learn more about this workflow. If you are still blocked please contact helpdesk from fmenu at top right of your screen or phone\n",
      "\n",
      "\u001b[1mPath:      \u001b[0m /Users/howardhuang/Code/my_own/DeepLearningWithPytorch-SecondEdition/.venv/lib/python3.10/site-packages/tensorboard_data_server/bin/server\n",
      "\u001b[1mIdentifier:\u001b[0m 186b1eb640607bd4f14d1714e906a2f5b8f0091f9e76a2169476ffdb7f87f5d8\n",
      "\u001b[1mParent:    \u001b[0m Python (21900)\n",
      "\n",
      "More info:\n",
      "https://www.internalfb.com/intern/appvote/186b1eb640607bd4f14d1714e906a2f5b8f0091f9e76a2169476ffdb7f87f5d8/?origin=santa&uuid=E6A5E9C9-27D7-5A14-9D61-33B71AE0840E&user_id=1366704400\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.16.2 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
