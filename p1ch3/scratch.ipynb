{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class FloatStorage in module torch:\n",
      "\n",
      "class FloatStorage(torch.storage._LegacyStorage)\n",
      " |  FloatStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      FloatStorage\n",
      " |      torch.storage._LegacyStorage\n",
      " |      torch.storage.TypedStorage\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  dtype = torch.float32\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.storage.TypedStorage:\n",
      " |  \n",
      " |  __copy__(self)\n",
      " |  \n",
      " |  __deepcopy__(self, memo)\n",
      " |  \n",
      " |  __getitem__(self, idx)\n",
      " |  \n",
      " |  __init__(self, *args, device=None, dtype=None, wrap_storage=None, _internal=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  __reduce__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setitem__(self, idx, value)\n",
      " |  \n",
      " |  __sizeof__(self)\n",
      " |      Size of object in memory, in bytes.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  bfloat16(self)\n",
      " |      Casts this storage to bfloat16 type\n",
      " |  \n",
      " |  bool(self)\n",
      " |      Casts this storage to bool type\n",
      " |  \n",
      " |  byte(self)\n",
      " |      Casts this storage to byte type\n",
      " |  \n",
      " |  char(self)\n",
      " |      Casts this storage to char type\n",
      " |  \n",
      " |  clone(self)\n",
      " |      Returns a copy of this storage\n",
      " |  \n",
      " |  complex_double(self)\n",
      " |      Casts this storage to complex double type\n",
      " |  \n",
      " |  complex_float(self)\n",
      " |      Casts this storage to complex float type\n",
      " |  \n",
      " |  copy_(self, source: ~T, non_blocking: bool = None)\n",
      " |  \n",
      " |  cpu(self)\n",
      " |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      " |  \n",
      " |  cuda(self, device=None, non_blocking=False, **kwargs) -> ~T\n",
      " |      Returns a copy of this object in CUDA memory.\n",
      " |      \n",
      " |      If this object is already in CUDA memory and on the correct device, then\n",
      " |      no copy is performed and the original object is returned.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (int): The destination GPU id. Defaults to the current device.\n",
      " |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      " |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      " |              the argument has no effect.\n",
      " |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      " |              the ``non_blocking`` argument.\n",
      " |  \n",
      " |  data_ptr(self)\n",
      " |  \n",
      " |  double(self)\n",
      " |      Casts this storage to double type\n",
      " |  \n",
      " |  element_size(self)\n",
      " |  \n",
      " |  fill_(self, value)\n",
      " |  \n",
      " |  float(self)\n",
      " |      Casts this storage to float type\n",
      " |  \n",
      " |  get_device(self) -> int\n",
      " |  \n",
      " |  half(self)\n",
      " |      Casts this storage to half type\n",
      " |  \n",
      " |  int(self)\n",
      " |      Casts this storage to int type\n",
      " |  \n",
      " |  is_pinned(self)\n",
      " |  \n",
      " |  is_shared(self)\n",
      " |  \n",
      " |  long(self)\n",
      " |      Casts this storage to long type\n",
      " |  \n",
      " |  nbytes(self)\n",
      " |  \n",
      " |  pickle_storage_type(self)\n",
      " |  \n",
      " |  pin_memory(self)\n",
      " |      Coppies the  storage to pinned memory, if it's not already pinned.\n",
      " |  \n",
      " |  resize_(self, size)\n",
      " |  \n",
      " |  share_memory_(self)\n",
      " |      Moves the storage to shared memory.\n",
      " |      \n",
      " |      This is a no-op for storages already in shared memory and for CUDA\n",
      " |      storages, which do not need to be moved for sharing across processes.\n",
      " |      Storages in shared memory cannot be resized.\n",
      " |      \n",
      " |      Returns: self\n",
      " |  \n",
      " |  short(self)\n",
      " |      Casts this storage to short type\n",
      " |  \n",
      " |  size(self)\n",
      " |  \n",
      " |  tolist(self)\n",
      " |      Returns a list containing the elements of this storage\n",
      " |  \n",
      " |  type(self, dtype: str = None, non_blocking: bool = False) -> Union[~T, str]\n",
      " |      Returns the type if `dtype` is not provided, else casts this object to\n",
      " |      the specified type.\n",
      " |      \n",
      " |      If this is already of the correct type, no copy is performed and the\n",
      " |      original object is returned.\n",
      " |      \n",
      " |      Args:\n",
      " |          dtype (type or string): The desired type\n",
      " |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      " |              and destination is on the GPU or vice versa, the copy is performed\n",
      " |              asynchronously with respect to the host. Otherwise, the argument\n",
      " |              has no effect.\n",
      " |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      " |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      " |  \n",
      " |  untyped(self)\n",
      " |      Returns the internal :class:`torch.UntypedStorage`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from torch.storage.TypedStorage:\n",
      " |  \n",
      " |  from_buffer(*args, **kwargs) from torch.storage._LegacyStorageMeta\n",
      " |  \n",
      " |  from_file(filename, shared, size) from torch.storage._LegacyStorageMeta\n",
      " |      from_file(filename, shared=False, size=0) -> Storage\n",
      " |      \n",
      " |      If `shared` is `True`, then memory is shared between all processes.\n",
      " |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      " |      the storage do not affect the file.\n",
      " |      \n",
      " |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      " |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      " |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      " |      created if needed.\n",
      " |      \n",
      " |      Args:\n",
      " |          filename (str): file name to map\n",
      " |          shared (bool): whether to share memory\n",
      " |          size (int): number of elements in the storage\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from torch.storage.TypedStorage:\n",
      " |  \n",
      " |  __new__(cls, *args, wrap_storage=None, dtype=None, device=None, _internal=False)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from torch.storage.TypedStorage:\n",
      " |  \n",
      " |  device\n",
      " |  \n",
      " |  is_cuda\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.storage.TypedStorage:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.storage.TypedStorage:\n",
      " |  \n",
      " |  __annotations__ = {'dtype': <class 'torch.dtype'>}\n",
      " |  \n",
      " |  is_sparse = False\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\howardhuang\\Documents\\MyCode\\DeepLearningWithPytorch-SecondEdition\\.venv\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "help(torch.Storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.FloatStorage"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=a[0]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1\n",
       " 1\n",
       "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 2]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1\n",
       " 1\n",
       "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 2]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 1.],\n",
      "        [5., 3.],\n",
      "        [2., 1.]])\n",
      "(2, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "print(points)\n",
    "print(points.stride())\n",
    "points_t = points.t()\n",
    "points_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.is_contiguous()\n",
    "points.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 5.0\n",
       " 2.0\n",
       " 1.0\n",
       " 3.0\n",
       " 1.0\n",
       "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont = points_t.contiguous()\n",
    "points_t_cont.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 2.],\n",
       "        [1., 3., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t_cont.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
